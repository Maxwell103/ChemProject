{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi all General\n",
    " \n",
    "Yesterday I learned about an interesting project that Peter Lambooij, teacher-researcher at Fontys, is conducting together with chemical experts from TU/e and other institutes. They try to create a robot that can conduct chemical experiments, which is very very ambitious and long-term.\n",
    " \n",
    "One of the many small steps in this research is extracting useful information from old chemical scientific charts. Like this:\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 817ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maxwe\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\maxwe\\anaconda3\\lib\\site-packages\\sklearn\\manifold\\_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the ResNet50 model\n",
    "model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# Load the images\n",
    "image_dir = 'ChemicalCharts/'\n",
    "images = []\n",
    "for filename in os.listdir(image_dir):\n",
    "    img_path = os.path.join(image_dir, filename)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    images.append(img)\n",
    "x = [image[:, :, :3] for image in images]\n",
    "\n",
    "# Preprocess the images\n",
    "x = preprocess_input(np.array(x))\n",
    "\n",
    "# Use the model to extract features from the images\n",
    "features = model.predict(x)\n",
    "\n",
    "# Concatenate the feature vectors into a 2D array\n",
    "features = features.reshape(len(images), -1)\n",
    "\n",
    "# Reduce the dimensionality of the feature vector using t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "tsne_features = tsne.fit_transform(features)\n",
    "\n",
    "# Plot the t-SNE features\n",
    "plt.scatter(tsne_features[:, 0], tsne_features[:, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x100 and 256x784)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29648\\761441085.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;31m# Generate fake graphs with the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[0mfake_graphs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[1;31m# Concatenate the real and fake graphs into one batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maxwe\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maxwe\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x100 and 256x784)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the graph dataset\n",
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, graph_dir):\n",
    "        self.graphs = []\n",
    "        self.graph_dir = graph_dir\n",
    "        \n",
    "        # Load graph images and extract graph data\n",
    "        for image_file in os.listdir(graph_dir):\n",
    "            graph_image = Image.open(os.path.join(graph_dir, image_file))\n",
    "            graph_data = preprocess_graph_image(graph_image)  # Extract graph data from image\n",
    "            self.graphs.append(graph_data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.graphs[index]\n",
    "    \n",
    "    \n",
    "def preprocess_graph_image(image):\n",
    "    # Convert image to grayscale\n",
    "    image = image.convert('L')\n",
    "    \n",
    "    # Threshold the image to convert it to black and white\n",
    "    threshold = 128\n",
    "    image = image.point(lambda x: 0 if x < threshold else 255)\n",
    "    \n",
    "    # Convert the image to a binary array\n",
    "    graph_data = np.array(image)\n",
    "    graph_data = (graph_data == 0).astype(float)\n",
    "    \n",
    "    # Convert the binary array to a flattened vector\n",
    "    graph_data = graph_data.flatten()\n",
    "    \n",
    "    return graph_data\n",
    "        \n",
    "# Define the generator network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Define the network layers\n",
    "        self.fc1 = nn.Linear(latent_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 256)\n",
    "        self.fc3 = nn.Linear(256, output_dim)\n",
    "        \n",
    "        # Define the activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define the discriminator network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Define the network layers\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "        # Define the activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(recon_data, data):\n",
    "    return nn.BCELoss()(recon_data, data)\n",
    "\n",
    "class GraphReplicationModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.encoder(x))\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define the hyperparameters\n",
    "batch_size = 32\n",
    "latent_dim = 100\n",
    "input_size = 784  # The flattened size of the graph images\n",
    "hidden_size = 256\n",
    "output_size = input_size\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create the data loader\n",
    "graph_dataset = GraphDataset(graph_dir='./OriginalCharts')\n",
    "graph_loader = DataLoader(dataset=graph_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create the model\n",
    "model = GraphReplicationModel(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
    "\n",
    "# Define the optimizers\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(graph_loader):\n",
    "        # Generate random noise for the generator\n",
    "        noise = torch.randn(batch_size, latent_dim)\n",
    "        \n",
    "        # Generate fake graphs with the generator\n",
    "        fake_graphs = model.decoder(noise)\n",
    "        \n",
    "        # Concatenate the real and fake graphs into one batch\n",
    "        real_graphs = data\n",
    "        all_graphs = torch.cat((real_graphs, fake_graphs), dim=0)\n",
    "        \n",
    "        # Create labels for the real and fake graphs\n",
    "        real_labels = torch.ones((batch_size, 1))\n",
    "        fake_labels = torch.zeros((batch_size, 1))\n",
    "        all_labels = torch.cat((real_labels, fake_labels), dim=0)\n",
    "        \n",
    "        # Train the discriminator\n",
    "        optimizer.zero_grad()\n",
    "        discriminator = Discriminator(input_dim=input_size)\n",
    "        discriminator_loss = loss_function(discriminator(all_graphs), all_labels)\n",
    "        discriminator_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Train the generator\n",
    "        optimizer.zero_grad()\n",
    "        generator = Generator(latent_dim=latent_dim, output_dim=output_size)\n",
    "        generator_loss = loss_function(discriminator(generator(noise)), real_labels)\n",
    "        generator_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Print the loss after each epoch\n",
    "    print('Epoch [{}/{}], Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(epoch+1, num_epochs, discriminator_loss.item(), generator_loss.item()))\n",
    "    \n",
    "# Generate a fake graph\n",
    "fake_graph = generator(torch.randn(1, latent_dim))\n",
    "fake_graph_data = fake_graph.detach().numpy()[0].reshape((28, 28))\n",
    "G = nx.from_numpy_matrix(fake_graph_data)\n",
    "nx.draw(G)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dataset = GraphDataset(graph_dir=r'C:\\Users\\maxwe\\Documents\\Github repos\\ChemProject\\OriginalCharts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of SymInts size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29648\\548738710.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlatent_space_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mGenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mgenerated_graphs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_space_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29648\\4219911128.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, latent_dim, output_dim)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# Define the activation functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maxwe\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of SymInts size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "# Generate new graphs using the trained VAE\n",
    "\n",
    "\n",
    "num_samples = 10\n",
    "latent_space_samples = torch.randn(num_samples, latent_dim)\n",
    "generator = Generator(latent_dim, output_dim)\n",
    "generated_graphs = Generator(latent_space_samples)\n",
    "\n",
    "\n",
    "\n",
    "# Plot the generated graphs\n",
    "fig, axes = plt.subplots(nrows=num_samples, ncols=1, figsize=(5,num_samples*5))\n",
    "for i in range(num_samples):\n",
    "    ax = axes[i]\n",
    "    G = nx.from_numpy_matrix(generated_graphs[i].detach().numpy())\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, font_weight='bold', ax=ax)\n",
    "    ax.set_title('Generated Graph {}'.format(i+1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of SymInts size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29648\\74878086.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlatent_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mGenerator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Generate some samples from the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29648\\4219911128.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, latent_dim, output_dim)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# Define the activation functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\maxwe\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of SymInts size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100\n",
    "output_dim = (50, 2)\n",
    "Generator = Generator(latent_dim, output_dim)\n",
    "\n",
    "# Generate some samples from the generator\n",
    "num_samples = 10\n",
    "latent_space_samples = torch.randn(num_samples, latent_dim)\n",
    "generated_graphs = Generator(latent_space_samples)\n",
    "\n",
    "# Plot the generated graphs\n",
    "plot_graphs(generated_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
